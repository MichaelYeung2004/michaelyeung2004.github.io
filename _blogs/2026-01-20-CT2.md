---
layout: blog
title: '利用链式法则和贝叶斯定理比较概率分布'
date: 2026-01-20
tags:
  - deep learning
  - paper
---

Exploiting Chain Rule and Bayes’ Theorem to Compare Probability Distributions

对于Comparing Probability Distributions with Conditional Transport，我们将原来的Navigator思想，**升华到了一个更根本的概率论高度**，直接与**概率链式法则 (Chain Rule)** 和 **贝叶斯定理 (Bayes' Theorem)** 这两大基石联系起来。

## 理论框架——链式法则与贝叶斯定理

**如何用概率论的基本法则来构建两个分布之间的关联？**

### 1. 概率链式法则 (Chain Rule)

概率链式法则是概率论中最基本的公式之一，它告诉我们如何分解一个联合概率分布。对于两个随机变量 $x$ 和 $y$，它们的联合分布 $\pi(x, y)$ 可以用两种方式分解：

1.  **方式一（前向分解）**：$\pi(x, y) = p_x(x) \times \pi(y\mid x)$
2.  **方式二（后向分解）**：$\pi(x, y) = p_y(y) \times \pi(x \mid y)$

我们想要构建一个连接真实分布 $p_x(x)$ 和生成分布 $p_y(y)$ 的“桥梁”，这个桥梁就是联合分布 $\pi(x, y)$。链式法则告诉我们有两种建桥的方式：

*   **前向建桥（Forward CT）**：我们先从真实世界中抽取一个样本 $x$（遵循 $p_x(x)$），然后**基于这个 $x$**，我们再通过一个条件分布 $\pi(y\mid x)$ 来选择一个与之匹配的生成样本 $y$。
*   **后向建桥（Backward CT）**：我们先从生成器中抽取一个样本 $y$（遵循 $p_y(y)$），然后**基于这个 $y$**，我们再通过一个条件分布 $\pi(x\mid y)$ 来寻找一个与之匹配的真实样本 $x$。

### 2. 贝叶斯定理 (Bayes' Theorem)

现在的问题是，那个条件分布 $\pi(y\mid x)$（我们之前称之为Navigator）到底应该长什么样？它不能是随便一个分布，它必须同时体现出真实样本 $x$ 和生成分布 $p_y(y)$ 的信息。

作者选择用贝叶斯定理来定义它。

我们先复习一下贝叶斯定理的经典形式：

$$ \text{后验概率} \propto \text{似然} \times \text{先验概率} $$

$$ P(\text{原因}\mid \text{结果}) \propto P(\text{结果}\mid \text{原因}) \times P(\text{原因}) $$

对于前向传输 $\pi(y\mid x)$，我们可以这样理解：

*   **问题**：给定一个**已观测到的真实数据 $x$**（结果），我们想要推断它最可能匹配的**生成数据 $y$**（原因）的概率分布。
*   **先验概率 (Prior)**：在我们看到任何真实数据 $x$ 之前，我们对 $y$ 的“先入为主”的看法是什么？很简单，我们认为 $y$ 应该来自于生成器的分布，所以**先验就是 $p_y(y)$**。这代表了生成器本身生成各个 $y$ 的“热门程度”。
*   **似然 (Likelihood)**：如果一个生成数据真的是 $y$，那么它和我们观测到的真实数据 $x$ “长得像”的可能性有多大？作者将这个“可能性”定义为一个与距离相关的函数，即**似然 $\propto e^{-d_\phi(x, y)}$**。这里的 $d_\phi(x,y)$ 依然是那个可学习的距离函数。两个点离得越近，似然就越大。
*   **后验概率 (Posterior)**：结合了先验和似然之后，我们得到的更新后的概率分布，就是我们的条件分布 $\pi(y\mid x)$。

把它们整合起来，就得到了论文中的**公式(1)**：

$$ \pi_\gamma(y\mid x) = \frac{e^{-d_\phi(x, y)} p_y(y)}{Q(x)}, \quad \text{其中 } Q(x) = \int e^{-d_\phi(x, y')} p_y(y') dy' $$

Q(x)是归一化常数

**这个公式现在有了贝叶斯解释：**
给定一个真实样本 $x$，它将被传输到一个生成样本 $y$ 的概率（后验），正比于 “$y$ 本身作为生成样本的普遍性（先验）” 与 “$y$ 和 $x$ 在特征上的相似性（似然）” 的乘积。

## 方法的核心机制

有了这个新框架，我们再来看CT的成本函数。

### 1. 前向与后向CT成本

**前向CT成本 (公式2)**：

$$ C(X \to Y) = \mathbb{E}_{x \sim p_x(x)} \mathbb{E}_{y \sim \pi(y\mid x)} [c(x,y)] $$

它的含义是：我们按照**前向建桥**方式 $\pi(x, y) = p_x(x) \pi(y \mid  x)$ 构建的联合分布，计算在该分布下，点对成本 $c(x,y)$ 的期望值。

*   **与Mode-Covering的联系**：论文在这里明确指出了它和KL散度的深刻联系。最小化这个成本，其效果类似于最小化 KL散度 $$KL(p_x \vert \vert p_y)$$。KL散度的性质是，只要某个地方 $p_x(x) > 0$，为了让KL散度不为无穷大，就必须有 $p_y(x) > 0$。也就是说，**真实数据存在的地方，生成数据也必须存在**。这正是“模式覆盖”的数学本质！

**后向CT成本 (公式4)**：
$$ C(X \leftarrow Y) = \mathbb{E}_{y \sim p_y(y)} \mathbb{E}_{x \sim \pi(x\mid y)} [c(x,y)] $$
它的含义是：我们按照**后向建桥**方式 $\pi(x, y) = p_y(y) \pi(x \mid y)$ 构建的联合分布，计算成本的期望值。

*   **与模式搜寻 (Mode-Seeking) 的联系**：同样，最小化这个成本，其效果类似于最小化反向KL散度 $$KL(p_y \vert \vert p_x)$$。反向KL散度允许在某些地方 $p_y(x)=0$ 即使 $p_x(x)>0$。也就是说，**生成的数据可以只专注于真实数据中密度最高、最典型的区域**，而忽略那些边缘、不典型的区域。这正是“模式搜寻”和可能导致“模式崩塌”的数学本质。

### 2. 平衡参数 $\rho$ (rho)

**总CT成本 (公式5)**：

$$ C_\rho(X, Y) := \rho C(X \to Y) + (1-\rho)C(X \leftarrow Y) $$

*   $\rho \in$ 是一个可以调节的**超参数**。
*   当 $\rho=1$ 时，模型只关心**模式覆盖**（可能会生成模糊图像）。
*   当 $\rho=0$ 时，模型只关心**模式搜寻**（很可能发生模式崩塌）。
*   当 $\rho=0.5$ 时（默认值），模型在两者之间取得平衡。

### 3. 基于共轭性的解析条件分布

在进入充满不确定性的现实世界（用样本近似）之前，作者先创建了一个理想化的沙盒。在这个沙盒里，所有的问题都有**解析解 (analytic solution)**，也就是说，我们可以用漂亮的数学公式直接把所有东西算出来，而不需要任何近似。

这个沙盒的作用是：
1.  **验证理论**：在一个可以精确计算的环境中，验证我们之前关于模式覆盖/搜寻的猜想是否正确。
2.  **提供洞察**：观察在这个理想环境中，各个参数是如何相互作用、共同达到最优解的，从而为理解更复杂的情况提供宝贵的直觉。

要获得解析解，我们需要一个特殊的数学性质，叫做**共轭性 (Conjugacy)**。在贝叶斯统计中，“共轭”指的是**先验分布 (Prior)** 和**后验分布 (Posterior)** 属于同一个概率分布家族。

回忆一下我们的前向Navigator公式（贝叶斯公式）：
$$ \pi(y\mid x) \propto \underbrace{p_y(y)}_{\text{先验}} \times \underbrace{e^{-d_\phi(x, y)}}_{\text{似然}} $$

如果我们的先验分布 $p_y(y)$ 和似然函数 $e^{-d_\phi(x, y)}$ 的形式“很搭”，使得它们的乘积（后验分布 $\pi(y\mid x)$）依然保持着和先验 $p_y(y)$ 类似的数学形式，我们就称它们是**共轭**的。

**最经典的共轭例子就是正态分布（高斯分布）。** 如果先验是正态分布，似然函数也是正态分布的形式，那么后验分布也必然是正态分布。

接下来，利用正态分布的共轭性，得到：

**公式(6): 单变量正态分布的例子**
*   **源分布 (真实)**：$p_x(x) = \mathcal{N}(0, 1)$，一个标准正态分布。
*   **目标分布 (生成)**：$p_y(y) = \mathcal{N}(0, e^\theta)$，一个均值为 0，方差为 $e^\theta$ 的正态分布。
*   **距离函数**：$d_\phi(x, y) = \frac{(x-y)^2}{2e^\phi}$。
*   **成本函数**：$c(x, y) = (x-y)^2$。

**为什么这个设置是“理想”的？**
因为这里的似然函数形式 $e^{-d_\phi(x, y)} = e^{-\frac{(x-y)^2}{2e^\phi}}$ 正好也是一个（未归一化的）**正态分布**的形式,而我们的先验 $p_y(y)$ 也是正态分布。正态乘以正态，结果还是正态。

因此，在这个设置下，前向导航器 $\pi(y\mid x)$ 和后向导航器 $\pi(x\mid y)$ 都可以被精确地计算出来，它们的结果也都是正态分布。论文在附录C中给出了详细的推导，最终得到：

*   **前向导航器**：$\pi(y\mid x) = \mathcal{N}(\sigma(\phi-\theta)x, \sigma(\phi-\theta)e^\phi)$
*   **后向导航器**：$\pi(x\mid y) = \mathcal{N}(\sigma(-\phi)y, \sigma(\phi))$
*   **前向成本**：$C(X \to Y) = \sigma(\phi-\theta)(e^\theta + \sigma(\phi-\theta))$
*   **后向成本**：$C(X \leftarrow Y) = \sigma(\phi)(1 + \sigma(\phi)e^\theta)$

这里的 $\sigma(\alpha) = 1/(1+e^{-\alpha})$ 是**Sigmoid函数**。在这个沙盒里，所有东西都有明确的数学表达式。

同时，作者引入了一个新的指标 $D(X, Y)$ 来**定量地**描述目标分布 $p_y$ 相对于源分布 $p_x$ 的行为倾向。

**定义: **$$ D(X, Y) = KL(p_x \vert \vert p_y) - KL(p_y \vert \vert p_x) $$

即前向KL散度与反向KL散度之差。

*   **如果 $D(X, Y) < 0$**：意味着 $KL(p_x \vert \vert p_y) < KL(p_y \vert \vert p_x)$。这表明，从KL散度的角度看，“让$p_y$覆盖$p_x$”比“让$p_y$被$p_x$覆盖”要“容易”得多。这对应于**模式覆盖 (mode-covering)** 行为。
*   **如果 $D(X, Y) > 0$**：意味着 $KL(p_y \vert \vert p_x)$ 更小。这对应于**模式搜寻 (mode-seeking)** 行为。

在我们的沙盒例子中，这个 $D(X, Y)$ 也可以被精确计算出来：
$$ D(X, Y) = \dots = \theta - \sinh(\theta)$$
其中 $\sinh(\theta)$ 是双曲正弦函数。

*   当 $\theta > 0$（生成分布的方差大于真实分布）时，$D(X, Y) < 0$，表现为**模式覆盖**。
*   当 $\theta < 0$（生成分布的方差小于真实分布）时，$D(X, Y) > 0$，表现为**模式搜寻**。

![image-20260120210647909](https://michaelyeung2004.github.io/assets/image-20260120210647909.png)

## 给定经验样本的近似CT

我们需要用已经获得的随机样本来构建真实分布的近似。

在每个训练步骤（iteration）中，我们都会有一个小批量（mini-batch）的数据：
*   一个从真实数据集中**无放回抽样**得到的批量：$\mathcal{X}_N = \{x_1, x_2, \dots, x_N\}$
*   一个通过生成器 $G_\theta$ 从随机噪声 $\epsilon_j$ 生成的批量：$\mathcal{Y}_M = \{y_1, y_2, \dots, y_M\}$

我们可以用这些样本来构建两个**经验概率分布 (Empirical Probability Distributions)**。

**公式(7): 真实数据的经验分布**
$$ \hat{p}_{\mathcal{X}_N}(x) = \frac{1}{N} \sum_{i=1}^N \delta(x - x_i) $$

**公式(8): 生成数据的经验分布**
$$ \hat{p}_{\mathcal{Y}_M}(y) = \frac{1}{M} \sum_{j=1}^M \delta(y - y_j) $$

现在，我们的核心策略就是：在理论CT的所有公式中，用这些离散的经验分布 $$\hat{p}_{\mathcal{X}_N}$$ 和 $$\hat{p}_{\mathcal{Y}_M}$$ 来替换掉我们未知的、连续的真实分布 $$p_x$$ 和 $$p_y$$。

这个替换策略带来的第一个美妙结果，就是大大简化了导航器的计算。让我们以**前向导航器**为例。

其理论公式(1)的分母中有一个棘手的积分：$Q(x) = \int e^{-d_\phi(x,y')} p_y(y') dy'$。
现在，我们将 $p_y(y')$ 替换为经验分布 $\hat{p}_{\mathcal{Y}_M}(y') = \frac{1}{M} \sum_{j=1}^M \delta(y' - y_j)$。利用狄拉克函数的积分性质，这个积分就奇迹般地**退化成了一个简单的求和**：
$$ Q(x) \approx \int e^{-d_\phi(x,y')} \left( \frac{1}{M} \sum_{j=1}^M \delta(y' - y_j) \right) dy' = \frac{1}{M} \sum_{j=1}^M e^{-d_\phi(x, y_j)} $$

于是，对于一个给定的源点 $x$，它被传输到**某一个特定的生成样本 $y_j$** 的（近似）条件概率，根据贝叶斯定理，就是：
$$ \hat{\pi}(y_j | x) = \frac{\text{似然} \times \text{先验}}{\text{证据}} = \frac{e^{-d_\phi(x, y_j)} \times \hat{p}_{\mathcal{Y}_M}(y_j)}{\sum_{l=1}^M e^{-d_\phi(x, y_l)} \hat{p}_{\mathcal{Y}_M}(y_l)} = \frac{e^{-d_\phi(x, y_j)} \times (1/M)}{\sum_{l=1}^M e^{-d_\phi(x, y_l)} \times (1/M)} = \frac{e^{-d_\phi(x, y_j)}}{\sum_{l=1}^M e^{-d_\phi(x, y_l)}} $$
这正是论文中的**公式(9)**所定义的**离散前向导航器 $\hat{\pi}_M(y_j|x, \phi)$**！

*   **$\hat{\pi}_M(y_j|x, \phi)$**：这个符号代表，给定一个源点 $x$ 和一个包含 $M$ 个生成样本的批量 $\mathcal{Y}_M$，点 $x$ 被传输到该批量中**第j个样本 $y_j$** 的概率。
*   **Softmax形式**：这个公式的形式是一个标准的**Softmax函数**。它计算了点 $x$ 与批量中所有生成样本 $\{y_l\}$ 之间的相似度（由 $e^{-d_\phi}$ 衡量），然后将这些相似度进行归一化，得到一个概率分布。这在计算上非常高效和稳定。

同样地，我们也可以得到**离散后向导航器 $\hat{\pi}_N(x_i|y, \phi)$**，它计算的是从一个给定的目标点 $y$ 到真实批量中第 $i$ 个样本 $x_i$ 的概率。

#### **3. 近似CT成本与最终的损失函数**

有了离散的导航器，我们就可以来近似CT成本了。

**近似前向CT成本 (公式10)**
首先，对于**一个**随机的源点 $x$，它到**一整个**生成批量 $\mathcal{Y}_M$ 的期望成本可以近似为：
$$ C_{\phi, \theta}(x \to \mathcal{Y}_M) = \sum_{j=1}^M c(x, y_j) \hat{\pi}_M(y_j | x, \phi) $$
然后，我们将这个成本对所有可能的源点 $x$ 和所有可能的生成批量 $\mathcal{Y}_M$ 取期望，就得到了**近似前向CT成本** $C_{\phi, \theta}(X \to \hat{Y}_M)$。

**近似后向CT成本 (公式11)** 的定义是完全对称的。

最后，我们将这两者结合起来，就得到了**近似的总CT成本 (公式12)**：
$$ C_{\phi, \theta, \rho}(\hat{X}_N, \hat{Y}_M) = \rho C_{\phi, \theta}(X \to \hat{Y}_M) + (1-\rho)C_{\phi, \theta}(\hat{X}_N \leftarrow Y) $$
这个公式仍然包含期望，还不是我们最终的损失函数。最终的损失函数是这个期望的**无偏样本估计 (unbiased sample estimate)**。

**最终的损失函数 (公式13)**
通过对公式(12)进行蒙特卡洛近似（即用我们当前手头的一个真实批量 $\mathcal{X}_N$ 和一个生成批量 $\mathcal{Y}_M$ 来代替完整的分布），我们可以得到最终在代码中使用的损失函数：
$$ \mathcal{L}_{\phi, \theta, \rho}(\mathcal{X}_N, \mathcal{Y}_M) = \frac{\rho}{N} \sum_{i=1}^N \sum_{j=1}^M c(x_i, y_j) \hat{\pi}_M(y_j|x_i, \phi) + \frac{1-\rho}{M} \sum_{j=1}^M \sum_{i=1}^N c(x_i, y_j) \hat{\pi}_N(x_i|y_j, \phi) $$
这个公式可以被重新整理成论文中公式(13)的紧凑形式：
$$ \mathcal{L}_{\phi, \theta, \rho}(\mathcal{X}_N, \mathcal{Y}_M) = \sum_{i=1}^N \sum_{j=1}^M c(x_i, y_j) \left( \frac{\rho}{N} \hat{\pi}_M(y_j|x_i, \phi) + \frac{1-\rho}{M} \hat{\pi}_N(x_i|y_j, \phi) \right) $$

**解读这个最终的损失函数**：
*   **核心计算**：它遍历了当前两个批量中**所有可能的配对** $(x_i, y_j)$，总共有 $N \times M$ 对。
*   **加权求和**：对于每一对 $(x_i, y_j)$，它的点对成本 $c(x_i, y_j)$ 被一个权重所加权。
*   **权重来源**：这个权重由两部分组成：
    1.  **前向权重**：从 $x_i$ 的视角看，它选择 $y_j$ 作为目标的概率 $\hat{\pi}_M(y_j|x_i, \phi)$，再乘以平衡系数 $\rho$ 和批大小的倒数 $1/N$。
    2.  **后向权重**：从 $y_j$ 的视角看，它选择 $x_i$ 作为目标的概率 $\hat{\pi}_N(x_i|y_j, \phi)$，再乘以 $(1-\rho)$ 和 $1/M$。
*   **整体含义**：整个损失函数就是所有 $N \times M$ 个点对成本的**双向加权平均**。

**Lemma 1** 是一个重要的理论保证，它指出当批量大小 $N, M \to \infty$ 时，我们这个基于样本的近似CT成本会**收敛**到理论上的真实CT成本。这确保了我们的近似在数学上是合理的。

---
**第三部分总结**

1.  **核心策略**：通过用**经验分布**（样本）代替未知的真实分布，将复杂的理论公式转化为可计算的实践形式。
2.  **关键简化**：理论中的**积分运算**被简化为对批量样本的**求和运算**，使得导航器可以高效地以**Softmax**形式计算。
3.  **最终损失函数**：推导出了一一个完全基于当前批次数据的、可计算、可微分的损失函数 $\mathcal{L}$。这个损失函数是对所有点对成本 $(x_i, y_j)$ 的**双向加权平均**。
4.  **理论保证**：**Lemma 1** 保证了这种近似在批量足够大时会收敛到真实值，证明了方法的合理性。

到此，我们已经拥有了一个可以在任何深度学习框架中实现的、具体的损失函数。但是，还有一个关键问题没有解决：成本函数 $c(x,y)$ 和导航器中的距离函数 $d_\phi(x,y)$ 应该如何为高维数据（如图像）设计？这引出了下一节，也是实践中至关重要的一步——特征编码器的引入。

